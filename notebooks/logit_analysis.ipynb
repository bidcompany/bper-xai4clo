{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "scripts_path = os.getcwd()\n",
    "env_file_path = os.path.join(scripts_path, 'env.txt')\n",
    "load_dotenv(env_file_path)\n",
    "main_path = os.getenv(\"MAIN_PATH\")\n",
    "\n",
    "sys.path.append(main_path)\n",
    "data_path = os.path.join(main_path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = os.path.join(data_path, 'EW_BusinessXai_v2.xlsx')\n",
    "samples = pd.read_excel(samples_file, sheet_name = 'EW_MODULI_SCORE_CORPORATE')\n",
    "predictions = pd.read_excel(samples_file, sheet_name = 'EW_SCORE_CORPORATE')\n",
    "kpi_map = pd.read_excel(os.path.join(data_path, 'mapping descrizioni KPI_v6.1.xlsx'))\n",
    "kpi_map = kpi_map.rename(columns={'ID':'KPI'})\n",
    "kpi_map = kpi_map[kpi_map.NOME_COLONNA_OUTPUT=='VALORE'].drop(['TIPOLOGIA_OUTPUT','COL_TO_TRANSPOSE','VALUE','CONSTANT_TO_ADD','TO_DROP','DESCRIZIONE','DATA_INIZIO_VALIDITA','DATA_FINE_VALIDITA'], axis = 1)\n",
    "\n",
    "weights = pd.read_excel(os.path.join(data_path, 'logit_weights.xlsx'), sheet_name='weights')\n",
    "weights = weights.set_index('Variabile').join(kpi_map[(kpi_map.KPI.isin(samples.KPI_CD.unique()))].set_index('CAMPO')).reset_index().sort_values(['MODELLO','MODULO_DS']).set_index('KPI')\n",
    "\n",
    "data = samples.pivot(index = 'ID', columns = 'KPI_CD', values='VALORE_QT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = lambda coefs, intercept, samples: 1/(1+np.exp(-1*(np.matmul(coefs,samples.T)+intercept)))\n",
    "log_odds_ratio = lambda coefs, intercept, samples: np.log(logit(coefs, intercept, samples)/(1-logit(coefs, intercept, samples)))\n",
    "contrib = lambda coefs, samples: coefs * samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.5201366 , 0.4798634 ],\n",
       "        [0.46080023, 0.53919977]]),\n",
       " array([[-0.08058999,  0.15712153]]))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'CORPORATE' \n",
    "module = 'Andamentale Interno'\n",
    "\n",
    "module_weights = weights[(weights.MODELLO == model) & (weights.MODULO_DS == module)]\n",
    "intercept = module_weights[module_weights.Variabile == 'intercept'].Coefficiente.values[0]*0.5\n",
    "coefs = module_weights[module_weights.Variabile!='intercept'].Coefficiente.sort_index()\n",
    "\n",
    "input_data = data.loc[:,coefs.index]\n",
    "prediction_ai = log_odds_ratio(coefs.values.reshape(1,-1), intercept, input_data.values)\n",
    "contribs_ai = contrib(coefs, input_data)\n",
    "prediction_ai\n",
    "\n",
    "lr_ai = LogisticRegression()\n",
    "lr_ai.fit(input_data, np.array([0,1]))\n",
    "lr_ai.coef_ = coefs.values.reshape(1,-1)\n",
    "lr_ai.intercept_ = np.array([intercept])\n",
    "\n",
    "lr_ai.predict_proba(input_data), prediction_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr_2543 = [0.2805,  -0.1635]\n",
    "distr_2544 = [ -0.5660]\n",
    "distr_2545 = [0.4860, -0.5930, -0.8117, -0.8117]\n",
    "distr_2546 = [0.2830, -0.7847, -0.7847]\n",
    "distr_2547 = [0.3227, -0.6792, -0.6792]\n",
    "distr_2548 = [1.8174, 0.4985, -0.2373, -0.5157,  -0.5157]\n",
    "distr_2549 = [0.9022, 0.1788, -0.1544,  -0.8492, -0.8492]\n",
    "distr_2550 = [0.7308, 0.3218, -0.3269, -0.9101,  -0.9101, -0.9101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_distr = np.array([distr_2543, distr_2544, distr_2545, distr_2546, distr_2547, distr_2548, distr_2549, distr_2550])\n",
    "xx, yy = create_dataset(ai_distr, 200)\n",
    "sum(lr_ai.predict(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['binned_ID45_UTIL_SUM2_SU_ACC_SUM2',\n",
       " 'binned_ID204_MAX_GG_SCONF_INC_AVGW6',\n",
       " 'binned_ID40_IMP_TOT_UTIL_SU_GIACE_MIN_AVGM2',\n",
       " 'binned_ID140_IMP_EFF_PROT_RICH_SU_SCAD_SUM3',\n",
       " 'binned_ID58_GG_DISP_CC_AVG3',\n",
       " 'binned_ID223_IMP_INSOLUTI_SU_SCADUTI_TS_SUM3',\n",
       " 'binned_ID35_FLAG_MAX_IMP_SCONF_GRT100_M1_RESPLIM',\n",
       " 'binned_ID180_NUM_RATE_IMPAGATE_MAX3_altro']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpi_map.set_index('KPI').loc[coefs.index,'CAMPO'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature 1 is constant and will be replaced with 0.\n"
     ]
    }
   ],
   "source": [
    "from omnixai.data.tabular import Tabular\n",
    "from omnixai.explainers.tabular import TabularExplainer\n",
    "from omnixai.preprocessing.tabular import TabularTransform\n",
    "from omnixai.explainers.tabular import GPTExplainer\n",
    "\n",
    "concat_data= pd.concat([pd.DataFrame(xx,columns = kpi_map.set_index('KPI').loc[coefs.index,'CAMPO'].values.tolist()), \n",
    "                        pd.Series(yy).to_frame('label')], axis = 1)\n",
    "\n",
    "tabular_concat_data = Tabular(\n",
    "    concat_data,\n",
    "    categorical_columns=[],\n",
    "    target_column='label'\n",
    ")\n",
    "\n",
    "tabular_xx = tabular_concat_data.remove_target_column()\n",
    "\n",
    "transformer = TabularTransform().fit(tabular_concat_data)\n",
    "class_names = transformer.class_names\n",
    "\n",
    "explainers = TabularExplainer(\n",
    "   explainers=[\"shap\", \"mace\"], # The explainers to apply\n",
    "   mode=\"classification\",                             # The task type\n",
    "   data = tabular_xx,                                   # The data for initializing the explainers\n",
    "   model = lr_ai,                                   # The ML model to explain\n",
    "   preprocess=lambda z: transformer.transform(z),     # Converts raw features into the model inputs\n",
    ")\n",
    "\n",
    "# analysis = explainers.explain(tabular_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55837021, 0.44162979],\n",
       "       [0.51037284, 0.48962716],\n",
       "       [0.79030226, 0.20969774],\n",
       "       [0.55019718, 0.44980282],\n",
       "       [0.29602912, 0.70397088],\n",
       "       [0.67109172, 0.32890828],\n",
       "       [0.3597023 , 0.6402977 ],\n",
       "       [0.67346857, 0.32653143],\n",
       "       [0.71904906, 0.28095094],\n",
       "       [0.43752009, 0.56247991],\n",
       "       [0.46364717, 0.53635283],\n",
       "       [0.77754952, 0.22245048],\n",
       "       [0.59680407, 0.40319593],\n",
       "       [0.78806844, 0.21193156],\n",
       "       [0.86175285, 0.13824715],\n",
       "       [0.63837642, 0.36162358],\n",
       "       [0.39149055, 0.60850945],\n",
       "       [0.6393787 , 0.3606213 ],\n",
       "       [0.93417653, 0.06582347],\n",
       "       [0.22128617, 0.77871383],\n",
       "       [0.28513922, 0.71486078],\n",
       "       [0.67346857, 0.32653143],\n",
       "       [0.40040796, 0.59959204],\n",
       "       [0.90299388, 0.09700612],\n",
       "       [0.96244926, 0.03755074],\n",
       "       [0.42527772, 0.57472228],\n",
       "       [0.50852741, 0.49147259],\n",
       "       [0.39511996, 0.60488004],\n",
       "       [0.75398049, 0.24601951],\n",
       "       [0.41467054, 0.58532946],\n",
       "       [0.28032363, 0.71967637],\n",
       "       [0.38439452, 0.61560548],\n",
       "       [0.79485288, 0.20514712],\n",
       "       [0.45440797, 0.54559203],\n",
       "       [0.35290156, 0.64709844],\n",
       "       [0.46920467, 0.53079533],\n",
       "       [0.62987165, 0.37012835],\n",
       "       [0.33447731, 0.66552269],\n",
       "       [0.2334261 , 0.7665739 ],\n",
       "       [0.68945991, 0.31054009],\n",
       "       [0.80814751, 0.19185249],\n",
       "       [0.86581613, 0.13418387],\n",
       "       [0.46840619, 0.53159381],\n",
       "       [0.46312339, 0.53687661],\n",
       "       [0.74940696, 0.25059304],\n",
       "       [0.49559565, 0.50440435],\n",
       "       [0.40177841, 0.59822159],\n",
       "       [0.25044759, 0.74955241],\n",
       "       [0.43820607, 0.56179393],\n",
       "       [0.882079  , 0.117921  ],\n",
       "       [0.38565335, 0.61434665],\n",
       "       [0.58706045, 0.41293955],\n",
       "       [0.46249795, 0.53750205],\n",
       "       [0.84725983, 0.15274017],\n",
       "       [0.73821587, 0.26178413],\n",
       "       [0.41381605, 0.58618395],\n",
       "       [0.51168179, 0.48831821],\n",
       "       [0.28236446, 0.71763554],\n",
       "       [0.85203158, 0.14796842],\n",
       "       [0.51879642, 0.48120358],\n",
       "       [0.50367406, 0.49632594],\n",
       "       [0.42527772, 0.57472228],\n",
       "       [0.8947364 , 0.1052636 ],\n",
       "       [0.62950196, 0.37049804],\n",
       "       [0.90896055, 0.09103945],\n",
       "       [0.42138727, 0.57861273],\n",
       "       [0.75622807, 0.24377193],\n",
       "       [0.88435587, 0.11564413],\n",
       "       [0.73725285, 0.26274715],\n",
       "       [0.63911629, 0.36088371],\n",
       "       [0.51326929, 0.48673071],\n",
       "       [0.42156437, 0.57843563],\n",
       "       [0.73821587, 0.26178413],\n",
       "       [0.78375777, 0.21624223],\n",
       "       [0.49157458, 0.50842542],\n",
       "       [0.53051476, 0.46948524],\n",
       "       [0.35724711, 0.64275289],\n",
       "       [0.27708216, 0.72291784],\n",
       "       [0.55983177, 0.44016823],\n",
       "       [0.88410631, 0.11589369],\n",
       "       [0.39490952, 0.60509048],\n",
       "       [0.53058096, 0.46941904],\n",
       "       [0.7802889 , 0.2197111 ],\n",
       "       [0.33860983, 0.66139017],\n",
       "       [0.64548415, 0.35451585],\n",
       "       [0.53402831, 0.46597169],\n",
       "       [0.70017744, 0.29982256],\n",
       "       [0.22128617, 0.77871383],\n",
       "       [0.74779416, 0.25220584],\n",
       "       [0.36617923, 0.63382077],\n",
       "       [0.46251728, 0.53748272],\n",
       "       [0.70380942, 0.29619058],\n",
       "       [0.46260392, 0.53739608],\n",
       "       [0.50062836, 0.49937164],\n",
       "       [0.53128643, 0.46871357],\n",
       "       [0.49464007, 0.50535993],\n",
       "       [0.52703188, 0.47296812],\n",
       "       [0.43644963, 0.56355037],\n",
       "       [0.42832866, 0.57167134],\n",
       "       [0.22294185, 0.77705815],\n",
       "       [0.70380942, 0.29619058],\n",
       "       [0.75721268, 0.24278732],\n",
       "       [0.40408377, 0.59591623],\n",
       "       [0.52353205, 0.47646795],\n",
       "       [0.24760311, 0.75239689],\n",
       "       [0.81293686, 0.18706314],\n",
       "       [0.57874804, 0.42125196],\n",
       "       [0.63585641, 0.36414359],\n",
       "       [0.86896804, 0.13103196],\n",
       "       [0.34376175, 0.65623825],\n",
       "       [0.59503956, 0.40496044],\n",
       "       [0.86377471, 0.13622529],\n",
       "       [0.54586424, 0.45413576],\n",
       "       [0.30262446, 0.69737554],\n",
       "       [0.91740569, 0.08259431],\n",
       "       [0.54186412, 0.45813588],\n",
       "       [0.49846179, 0.50153821],\n",
       "       [0.72820085, 0.27179915],\n",
       "       [0.35458969, 0.64541031],\n",
       "       [0.5496976 , 0.4503024 ],\n",
       "       [0.96449983, 0.03550017],\n",
       "       [0.46260392, 0.53739608],\n",
       "       [0.39149055, 0.60850945],\n",
       "       [0.7870101 , 0.2129899 ],\n",
       "       [0.17729359, 0.82270641],\n",
       "       [0.882079  , 0.117921  ],\n",
       "       [0.71727741, 0.28272259],\n",
       "       [0.79632594, 0.20367406],\n",
       "       [0.36576276, 0.63423724],\n",
       "       [0.22128617, 0.77871383],\n",
       "       [0.73581512, 0.26418488],\n",
       "       [0.70464146, 0.29535854],\n",
       "       [0.72293905, 0.27706095],\n",
       "       [0.60944915, 0.39055085],\n",
       "       [0.35724711, 0.64275289],\n",
       "       [0.70794737, 0.29205263],\n",
       "       [0.39802429, 0.60197571],\n",
       "       [0.88748709, 0.11251291],\n",
       "       [0.30264087, 0.69735913],\n",
       "       [0.69118833, 0.30881167],\n",
       "       [0.64008505, 0.35991495],\n",
       "       [0.8459228 , 0.1540772 ],\n",
       "       [0.62987165, 0.37012835],\n",
       "       [0.77392243, 0.22607757],\n",
       "       [0.42244685, 0.57755315],\n",
       "       [0.71199089, 0.28800911],\n",
       "       [0.5076505 , 0.4923495 ],\n",
       "       [0.22294185, 0.77705815],\n",
       "       [0.31423679, 0.68576321],\n",
       "       [0.65515596, 0.34484404],\n",
       "       [0.76607688, 0.23392312],\n",
       "       [0.44435252, 0.55564748],\n",
       "       [0.49157458, 0.50842542],\n",
       "       [0.56450256, 0.43549744],\n",
       "       [0.38235783, 0.61764217],\n",
       "       [0.42064622, 0.57935378],\n",
       "       [0.80532352, 0.19467648],\n",
       "       [0.49006397, 0.50993603],\n",
       "       [0.46260392, 0.53739608],\n",
       "       [0.78411942, 0.21588058],\n",
       "       [0.77064552, 0.22935448],\n",
       "       [0.68259465, 0.31740535],\n",
       "       [0.44486136, 0.55513864],\n",
       "       [0.91056311, 0.08943689],\n",
       "       [0.35724711, 0.64275289],\n",
       "       [0.43077546, 0.56922454],\n",
       "       [0.6361085 , 0.3638915 ],\n",
       "       [0.86393172, 0.13606828],\n",
       "       [0.63145126, 0.36854874],\n",
       "       [0.92335003, 0.07664997],\n",
       "       [0.35724711, 0.64275289],\n",
       "       [0.661733  , 0.338267  ],\n",
       "       [0.69238268, 0.30761732],\n",
       "       [0.86159306, 0.13840694],\n",
       "       [0.59418667, 0.40581333],\n",
       "       [0.67755297, 0.32244703],\n",
       "       [0.8115555 , 0.1884445 ],\n",
       "       [0.55565409, 0.44434591],\n",
       "       [0.79751186, 0.20248814],\n",
       "       [0.63545738, 0.36454262],\n",
       "       [0.79701649, 0.20298351],\n",
       "       [0.41842667, 0.58157333],\n",
       "       [0.85762813, 0.14237187],\n",
       "       [0.32032151, 0.67967849],\n",
       "       [0.6368617 , 0.3631383 ],\n",
       "       [0.7690654 , 0.2309346 ],\n",
       "       [0.31423679, 0.68576321],\n",
       "       [0.39602048, 0.60397952],\n",
       "       [0.32873732, 0.67126268],\n",
       "       [0.91733894, 0.08266106],\n",
       "       [0.61763769, 0.38236231],\n",
       "       [0.91499791, 0.08500209],\n",
       "       [0.69174109, 0.30825891],\n",
       "       [0.28032363, 0.71967637],\n",
       "       [0.73549446, 0.26450554],\n",
       "       [0.72742015, 0.27257985],\n",
       "       [0.66123563, 0.33876437],\n",
       "       [0.49807246, 0.50192754],\n",
       "       [0.55439033, 0.44560967],\n",
       "       [0.62298327, 0.37701673]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_ai.predict_proba(transformer.transform(tabular_xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40763509, 0.824896  ]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 150 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "Feature 1 is constant and will be replaced with 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided feature importance scores, the example is classified as label_1 primarily due to the following factors:\n",
      "\n",
      "1. \"binned_ID223_IMP_INSOLUTI_SU_SCADUTI_TS_SUM3 = 0.4985\": This feature has the highest positive importance score, indicating a strong positive influence on the prediction towards label_1.\n",
      "\n",
      "2. \"binned_ID140_IMP_EFF_PROT_RICH_SU_SCAD_SUM3 = 0.283\": This feature also has a positive importance score, contributing to the prediction towards label_1.\n",
      "\n",
      "To change the predicted label, you can modify the values of the following features:\n",
      "\n",
      "1. To change the predicted label to label_0, set \"binned_ID40_IMP_TOT_UTIL_SU_GIACE_MIN_AVGM2\" to a value lower than -0.68868125.\n",
      "\n",
      "2. To change the predicted label to label_0, set \"binned_ID35_FLAG_MAX_IMP_SCONF_GRT100_M1_RESPLIM\" to a value lower than -0.24125000000000002.\n"
     ]
    }
   ],
   "source": [
    "explainer = GPTExplainer(\n",
    "    training_data=tabular_xx,\n",
    "    # predict_function=lambda x: lr_ai.predict_proba(transformer.transform(x)),\n",
    "    predict_function=lambda x: np.random.rand(transformer.transform(x).shape[0],2),\n",
    "    apikey=\"\"\n",
    ")\n",
    "\n",
    "explanations = explainer.explain(tabular_xx[11])\n",
    "print(explanations.get_explanations(index=0)[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from omnixai.data.tabular import Tabular\n",
    "\n",
    "import sklearn\n",
    "import xgboost\n",
    "\n",
    "transformer = TabularTransform().fit(tabular_data)\n",
    "class_names = transformer.class_names\n",
    "x = transformer.transform(tabular_data)\n",
    "\n",
    "train, test, train_labels, test_labels = \\\n",
    "    sklearn.model_selection.train_test_split(x[:, :-1], x[:, -1], train_size=0.80)\n",
    "\n",
    "mm = xgboost.XGBClassifier(n_estimators=300, max_depth=5)\n",
    "mm.fit(train, train_labels)\n",
    "\n",
    "train_data = transformer.invert(train)\n",
    "test_data = transformer.invert(test)\n",
    "datas = transformer.invert(input_data.values)\n",
    "\n",
    "# Initialize a TabularExplainer\n",
    "explainers = TabularExplainer(\n",
    "   explainers=[\"shap\",\"mace\"], # The explainers to apply\n",
    "   mode=\"classification\",                             # The task type\n",
    "   data=train_data,                                   # The data for initializing the explainers\n",
    "   model=lr_legacy,                                   # The ML model to explain\n",
    "   preprocess=lambda z: transformer.transform(z),     # Converts raw features into the model inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = explainers.explain(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = GPTExplainer(\n",
    "    training_data=tabular_data,\n",
    "    predict_function=lambda x: mm.predict_proba(transformer.transform(x)),\n",
    "    apikey=\"sk-\"\n",
    ")\n",
    "\n",
    "explanations = explainer.explain(train_data[38])\n",
    "print(explanations.get_explanations(index=0)[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.85981482, 0.14018518],\n",
       "        [0.83281633, 0.16718367]]),\n",
       " array([[-1.81375277, -1.60572007]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = 'Centrale Rischi'\n",
    "\n",
    "module_weights = weights[(weights.MODELLO == model) & (weights.MODULO_DS == module)]\n",
    "intercept = module_weights[module_weights.Variabile == 'Intercept'].Coefficiente.values[0]\n",
    "coefs = module_weights[module_weights.Variabile!='Intercept'].Coefficiente.sort_index()\n",
    "\n",
    "input_data = data.loc[:,coefs.index]\n",
    "prediction_cr = log_odds_ratio(coefs.values.reshape(1,-1), intercept, input_data.values)\n",
    "contribs_cr = contrib(coefs, input_data)\n",
    "prediction_cr\n",
    "\n",
    "lr_cr = LogisticRegression()\n",
    "lr_cr.fit(input_data, np.array([0,1]))\n",
    "lr_cr.coef_ = coefs.values.reshape(1,-1)\n",
    "lr_cr.intercept_ = np.array([intercept])\n",
    "\n",
    "lr_cr.predict_proba(input_data), prediction_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.91001194, 0.08998806],\n",
       "        [0.9280303 , 0.0719697 ]]),\n",
       " array([[-2.31378076, -2.55681914]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = 'Bilanci'\n",
    "module_data = samples[(samples.MODELLO == model) & (samples.MODULO_DS == module)].pivot(index = 'ID', columns = 'KPI_CD', values='VALORE_QT')\n",
    "\n",
    "module_weights = weights[(weights.MODELLO == model) & (weights.MODULO_DS == module)]\n",
    "intercept = module_weights[module_weights.Variabile == 'Intercept'].Coefficiente.values[0]\n",
    "coefs = module_weights[module_weights.Variabile!='Intercept'].Coefficiente.sort_index()\n",
    "\n",
    "input_data = data.loc[:,coefs.index]\n",
    "prediction_bil = log_odds_ratio(coefs.values.reshape(1,-1), intercept, input_data.values)\n",
    "contribs_bil = contrib(coefs, input_data)\n",
    "prediction_bil\n",
    "\n",
    "lr_bil = LogisticRegression()\n",
    "lr_bil.fit(input_data, np.array([0,1]))\n",
    "lr_bil.coef_ = coefs.values.reshape(1,-1)\n",
    "lr_bil.intercept_ = np.array([intercept])\n",
    "\n",
    "lr_bil.predict_proba(input_data), prediction_bil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_trans = np.array([0.732320845, 0.643310368])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEGACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_transformation = os.path.join(data_path,'integrazione_transformation.xlsx')\n",
    "transf = pd.read_excel(path_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_binning(vals, table):\n",
    "    tt = list(table.itertuples(index = False, name = None))\n",
    "    bins_mapper = {pd.IntervalIndex.from_tuples([(x[0], x[1])], closed='left')[0]: x[2] for x in tt}\n",
    "    bins = pd.IntervalIndex.from_tuples([(x[0], x[1]) for x in tt], closed = 'left')\n",
    "    return pd.Series(pd.cut(vals.reshape(-1), bins)).replace(bins_mapper).astype(float).values.reshape(-1,1)\n",
    "\n",
    "table_ai = transf[(transf.Variabile == 'score_AI')& (transf.Bin != 'Missing')].loc[:, ['LB', 'UB', 'WoE']]\n",
    "bin_score_ai = apply_binning(prediction_ai, table_ai)\n",
    "\n",
    "table_cr = transf[(transf.Variabile == 'score_cr')& (transf.Bin != 'Missing')].loc[:, ['LB', 'UB', 'WoE']]\n",
    "bin_score_cr = apply_binning(prediction_cr,table_cr)\n",
    "\n",
    "table_bil = transf[(transf.Variabile == 'score_bil') & (transf.Bin != 'Missing')].loc[:, ['LB', 'UB', 'WoE']]\n",
    "bin_score_bil = apply_binning(prediction_bil,table_bil)\n",
    "\n",
    "table_trans = transf[(transf.Variabile == 'score_trans') & (transf.Bin != 'Missing')].loc[:, ['LB', 'UB', 'WoE']]\n",
    "bin_score_trans = apply_binning(prediction_trans,table_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = 'Integrazione'\n",
    "legacy_data = pd.DataFrame(np.concatenate([bin_score_ai, bin_score_cr, bin_score_bil, bin_score_trans], axis = 1), columns = ['binned_score_AI','binned_score_cr','binned_score_bil', 'binned_score_trans'])\n",
    "\n",
    "module_weights = weights[(weights.MODELLO == model) & (weights.MODULO_DS == module)]\n",
    "intercept = module_weights[module_weights.Variabile == 'Intercept'].Coefficiente.values[0]\n",
    "coefs = module_weights[module_weights.Variabile!='Intercept'].set_index('Variabile').Coefficiente\n",
    "\n",
    "input_data = legacy_data.loc[:,coefs.index]\n",
    "prediction_legacy = log_odds_ratio(coefs.values.reshape(1,-1), intercept, input_data.values)\n",
    "contribs_legacy = contrib(coefs, input_data)\n",
    "prediction_legacy, contribs_legacy\n",
    "\n",
    "lr_legacy = LogisticRegression()\n",
    "lr_legacy.fit(input_data.values, np.array([0,1]))\n",
    "lr_legacy.coef_ = coefs.values.reshape(1,-1)\n",
    "lr_legacy.intercept_ = np.array([intercept])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_values = [2.0646, 1.2387, 0.3632, 0.0000, -0.4019, -0.9806, -1.4795]\n",
    "bil_values = [1.3922, 0.7261, 0.0777, -0.1502, -0.7039]\n",
    "cr_values = [1.7992, 1.0283, 0.3965, 0.1738, 0.0055, -0.5626, -1.0893, -1.5130]\n",
    "trans_values = [1.7341, 0.9211, 0.2307, -0.2502, -0.6687, -0.6836]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_dataset(distr, size):\n",
    "    \"\"\"\n",
    "    Crea un dataset basato sui valori possibili per n variabili.\n",
    "\n",
    "    Args:\n",
    "    - distr (list of lists): Una lista di liste, dove ogni lista interna contiene \n",
    "      i valori possibili per una feature.\n",
    "    - size (int): La dimensione del dataset di output.\n",
    "\n",
    "    Returns:\n",
    "    - dataset (ndarray): Il dataset generato.\n",
    "    \"\"\"\n",
    "\n",
    "    # Verifica che distr sia una lista di liste\n",
    "    if not all(isinstance(i, list) for i in distr):\n",
    "        raise ValueError(\"Ogni elemento di distr deve essere una lista\")\n",
    "\n",
    "    # Estrazione casuale dei valori per ciascuna feature\n",
    "    features = [np.random.choice(feature_values, size) for feature_values in distr]\n",
    "\n",
    "    # Combinazione delle features per formare il dataset\n",
    "    dataset = np.column_stack(features)\n",
    "\n",
    "    labels = [np.random.choice([0,1]) for x in range(size)]\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "vv, yy = create_dataset([ai_values, bil_values, cr_values, trans_values],100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "upsampled_data, target = make_classification(n_samples=100, n_features=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bper_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
